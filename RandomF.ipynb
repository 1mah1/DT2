{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "19M_XhuMsSgAXBFPaTBclp8Lh9xS1X-FB",
      "authorship_tag": "ABX9TyPG1hgQ8EyhzxPjyc98PJtJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1mah1/DT2/blob/main/RandomF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install img2vec-pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "HO1n_ofTpWyz",
        "outputId": "6c82dc43-dc0c-4549-ea21-6d305bb05e73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting img2vec-pytorch\n",
            "  Downloading img2vec_pytorch-1.0.1-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from img2vec-pytorch) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from img2vec-pytorch) (0.20.1+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from img2vec-pytorch) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->img2vec-pytorch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->img2vec-pytorch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->img2vec-pytorch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->img2vec-pytorch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->img2vec-pytorch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->img2vec-pytorch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->img2vec-pytorch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->img2vec-pytorch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->img2vec-pytorch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->img2vec-pytorch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->img2vec-pytorch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->img2vec-pytorch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->img2vec-pytorch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->img2vec-pytorch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->img2vec-pytorch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->img2vec-pytorch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->img2vec-pytorch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->img2vec-pytorch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->img2vec-pytorch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->img2vec-pytorch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->img2vec-pytorch) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->img2vec-pytorch) (3.0.2)\n",
            "Downloading img2vec_pytorch-1.0.1-py3-none-any.whl (6.9 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m115.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m90.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m91.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, img2vec-pytorch\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed img2vec-pytorch-1.0.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from img2vec_pytorch import Img2Vec\n",
        "from skimage.transform import resize\n",
        "from skimage.io import imread\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from PIL import Image\n",
        "from sklearn.metrics import log_loss"
      ],
      "metadata": {
        "id": "YSXhLmiEpt1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img2vec = Img2Vec()\n",
        "input_dir = \"/content/drive/MyDrive/Python/garbage_classification\"\n",
        "# categories = ['cardboard', 'green-glass', 'metal', 'plastic']\n",
        "categories = ['cardboard', 'green-glass', 'metal']\n",
        "image_size = 224"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1ryLY0Vp07N",
        "outputId": "cea31ac9-74b4-48d4-e3b0-abaf69a3c69e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 164MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data = {}\n",
        "labels = []\n",
        "features =[]\n",
        "\n",
        "for category_indx, category in enumerate(categories):\n",
        "    file_count = 0\n",
        "    for file in os.listdir((os.path.join(input_dir, category))):\n",
        "        # if file_count >= images_per_category:\n",
        "        #     break\n",
        "        img_path = os.path.join(input_dir, category, file)\n",
        "        img = imread(img_path)\n",
        "        img = resize(img, (image_size, image_size))\n",
        "        img = Image.fromarray((img * 255).astype(np.uint8))\n",
        "        img_features = img2vec.get_vec(img)\n",
        "        features.append(img_features)\n",
        "        labels.append(category_indx)\n",
        "        file_count += 1\n",
        "\n",
        "    # data[['input'][category_indx]] = features\n",
        "    # data[['output'][category_indx]] = features\n",
        "# data = np.asarray(data)\n",
        "features = np.asarray(features)\n",
        "labels = np.asarray(labels)"
      ],
      "metadata": {
        "id": "eLZ0r23CqBzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print dataset information\n",
        "print(f\"Total images loaded: {len(features)}\")\n",
        "for category_idx, category in enumerate(categories):\n",
        "    count = np.sum(labels == category_idx)\n",
        "    print(f\"{category}: {count} images\")\n",
        "print(f\"Feature vector length: {features.shape[1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98oEzyBL40es",
        "outputId": "945044a4-2b16-4d3d-d1b0-9549255be9ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images loaded: 2289\n",
            "cardboard: 891 images\n",
            "green-glass: 629 images\n",
            "metal: 769 images\n",
            "Feature vector length: 512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# x_train, x_test, y_train, y_test = train_test_split(\n",
        "#     data,\n",
        "#     labels,\n",
        "#     test_size=0.2,\n",
        "#     val_size=0.2,\n",
        "#     shuffle=True,\n",
        "#     stratify=labels,\n",
        "#     random_state=42\n",
        "# )"
      ],
      "metadata": {
        "id": "tsDdVXh74Qnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_size=0.2\n",
        "val_size=0.2\n",
        "random_state=42\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "    features,\n",
        "    labels,\n",
        "    test_size=test_size,\n",
        "    random_state=random_state,\n",
        "    stratify=labels  # Maintain class distribution\n",
        ")\n",
        "\n",
        "adjusted_val_size = val_size / (1 - test_size)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_temp,\n",
        "    y_temp,\n",
        "    test_size=adjusted_val_size,\n",
        "    random_state=random_state,\n",
        "    stratify=y_temp  # Maintain class distribution\n",
        ")\n",
        "\n",
        "# Create a dictionary with the split datasets\n",
        "# Extract data from split_data dictionary\n",
        "\n",
        "# X_train = split_data['train']['features']\n",
        "# y_train = split_data['train']['labels']\n",
        "# X_val = split_data['validation']['features']\n",
        "# y_val = split_data['validation']['labels']\n",
        "# X_test = split_data['test']['features']\n",
        "# y_test = split_data['test']['labels']\n",
        "\n",
        "# split_data = {\n",
        "#     'train': {\n",
        "#         'features': X_train,\n",
        "#         'labels': y_train\n",
        "#     },\n",
        "#     'validation': {\n",
        "#         'features': X_val,\n",
        "#         'labels': y_val\n",
        "#     },\n",
        "#     'test': {\n",
        "#         'features': X_test,\n",
        "#         'labels': y_test\n",
        "#     }\n",
        "# }\n",
        "\n",
        "# Print split sizes\n",
        "print(f\"Total samples: {len(features)}\")\n",
        "print(f\"Training samples: {len(X_train)} ({len(X_train)/len(features):.1%})\")\n",
        "print(f\"Validation samples: {len(X_val)} ({len(X_val)/len(features):.1%})\")\n",
        "print(f\"Test samples: {len(X_test)} ({len(X_test)/len(features):.1%})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzPnW5cp37ne",
        "outputId": "41c643c9-b692-4463-a125-2378d18e66d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total samples: 2289\n",
            "Training samples: 1373 (60.0%)\n",
            "Validation samples: 458 (20.0%)\n",
            "Test samples: 458 (20.0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# K-Fold\n",
        "n_splits = 5\n",
        "random_state = 42\n",
        "kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "\n",
        "fold_scores = []\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train), 1):\n",
        "    X_train_fold = X_train[train_idx]\n",
        "    y_train_fold = y_train[train_idx]\n",
        "    X_val_fold = X_train[val_idx]\n",
        "    y_val_fold = y_train[val_idx]\n",
        "\n",
        "    model = RandomForestClassifier()\n",
        "    model.fit(X_train_fold, y_train_fold)\n",
        "    y_pred = model.predict(X_val_fold)\n",
        "\n",
        "    fold_accuracy = accuracy_score(y_val_fold, y_pred)\n",
        "    fold_scores.append(fold_accuracy)\n",
        "\n",
        "    print(f\"Fold {fold} Accuracy: {fold_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd5q0t55znDj",
        "outputId": "f5b2d328-057b-4e53-c481-8c0a2dbd6773"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Accuracy: 0.9818\n",
            "Fold 2 Accuracy: 0.9673\n",
            "Fold 3 Accuracy: 0.9564\n",
            "Fold 4 Accuracy: 0.9672\n",
            "Fold 5 Accuracy: 0.9453\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(range(1, n_splits + 1), fold_scores, marker='o', linestyle='-', color='b', label='Validation Accuracy')\n",
        "plt.xlabel('Fold')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title(f'{n_splits}-Fold Cross-Validation Accuracy')\n",
        "plt.ylim(0, 1)\n",
        "plt.xticks(range(1, n_splits + 1))\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "28_DWmMYQOj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fold_losses = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train), 1):\n",
        "    X_train_fold = X_train[train_idx]\n",
        "    y_train_fold = y_train[train_idx]\n",
        "    X_val_fold = X_train[val_idx]\n",
        "    y_val_fold = y_train[val_idx]\n",
        "\n",
        "    model = RandomForestClassifier()\n",
        "    model.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    y_val_proba = model.predict_proba(X_val_fold)\n",
        "    fold_loss = log_loss(y_val_fold, y_val_proba)\n",
        "\n",
        "    fold_losses.append(fold_loss)\n",
        "    print(f\"Fold {fold} Log Loss: {fold_loss:.4f}\")\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(range(1, len(fold_losses) + 1), fold_losses, marker='o', linestyle='-', color='r', label='Validation Log Loss')\n",
        "plt.xlabel('Fold')\n",
        "plt.ylabel('Log Loss')\n",
        "plt.title(f'{n_splits}-Fold Cross-Validation Log Loss')\n",
        "plt.ylim(0, max(fold_losses) + 0.1)\n",
        "plt.xticks(range(1, len(fold_losses) + 1))\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "PC8vg8MPQhXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_val_fold)\n",
        "fold_accuracy = accuracy_score(y_val_fold, y_pred)\n",
        "fold_scores.append(fold_accuracy)\n",
        "print(f\"Fold {fold} Accuracy: {fold_accuracy:.4f}\")\n",
        "# print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "print(\"\\nDetailed classification report:\")\n",
        "print(classification_report(y_val_fold, y_pred, target_names=categories))"
      ],
      "metadata": {
        "id": "xOh7rw_L1j6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "cm = confusion_matrix(y_val_fold, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens',\n",
        "            xticklabels=categories,\n",
        "            yticklabels=categories)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yPnbNgfc8yQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cv_mean = np.mean(fold_scores)\n",
        "cv_std = np.std(fold_scores)\n",
        "print(f\"\\nCross-validation Mean Accuracy: {cv_mean:.4f} (±{cv_std:.4f})\")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "val_score = accuracy_score(y_val, model.predict(X_val))\n",
        "test_score = accuracy_score(y_test, model.predict(X_test))\n",
        "\n",
        "print(f\"Validation Set Accuracy: {val_score:.4f}\")\n",
        "print(f\"Test Set Accuracy: {test_score:.4f}\")\n"
      ],
      "metadata": {
        "id": "9wRmcDwyBZ5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(range(1, n_splits + 1), fold_scores, marker='o', linestyle='-', color='b', label='Validation Accuracy')\n",
        "plt.xlabel('Fold')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title(f'{n_splits}-Fold Cross-Validation Accuracy')\n",
        "plt.ylim(0, 1)\n",
        "plt.xticks(range(1, n_splits + 1))\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "rRe5AE00KrCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_points=10\n",
        "train_sizes = np.linspace(0.1, 1.0, n_points)\n",
        "train_scores = []\n",
        "val_scores = []\n",
        "\n",
        "for size in train_sizes:\n",
        "    n_samples = int(len(X_train) * size)\n",
        "\n",
        "    cv_scores = cross_val_score(\n",
        "        model, X_train[:n_samples], y_train[:n_samples],\n",
        "        cv=cv, n_jobs=-1\n",
        "    )\n",
        "\n",
        "    model.fit(X_train[:n_samples], y_train[:n_samples])\n",
        "    val_score = model.score(X_val, y_val)\n",
        "\n",
        "    train_scores.append(cv_scores)\n",
        "    val_scores.append(val_score)\n",
        "\n",
        "train_scores = np.array(train_scores)\n",
        "val_scores = np.array(val_scores)\n",
        "\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "val_mean = val_scores\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plt.plot(train_sizes * len(X_train), train_mean,\n",
        "         label='Training Score', color='blue', marker='o')\n",
        "plt.fill_between(train_sizes * len(X_train),\n",
        "                 train_mean - train_std, train_mean + train_std,\n",
        "                 alpha=0.15, color='blue')\n",
        "\n",
        "plt.plot(train_sizes * len(X_train), val_mean,\n",
        "         label='Validation Score', color='green', marker='o')\n",
        "\n",
        "plt.xlabel('Training Examples')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Learning Curves')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.text(0.02, 0.02,\n",
        "         f'Final Training Score: {train_mean[-1]:.4f}\\n'\n",
        "         f'Final Validation Score: {val_mean[-1]:.4f}',\n",
        "         transform=plt.gca().transAxes,\n",
        "         bbox=dict(facecolor='white', alpha=0.8))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "lWZ7RmTk-7cB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}