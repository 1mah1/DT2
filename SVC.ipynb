{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1USNuneLuvNe__tw60HDv1p1EaQ_aKNdj",
      "authorship_tag": "ABX9TyOLk4DbnKIBfmkv5x9SKJgz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1mah1/DT2/blob/main/SVC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "K5H7VFD5gOeq",
        "outputId": "1e16c6c3-5e6c-4d1e-8051-7d84f45a5200"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting img2vec-pytorch\n",
            "  Downloading img2vec_pytorch-1.0.1-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from img2vec-pytorch) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from img2vec-pytorch) (0.20.1+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from img2vec-pytorch) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->img2vec-pytorch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->img2vec-pytorch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->img2vec-pytorch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->img2vec-pytorch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->img2vec-pytorch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->img2vec-pytorch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->img2vec-pytorch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->img2vec-pytorch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->img2vec-pytorch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->img2vec-pytorch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->img2vec-pytorch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->img2vec-pytorch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->img2vec-pytorch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->img2vec-pytorch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->img2vec-pytorch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->img2vec-pytorch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->img2vec-pytorch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->img2vec-pytorch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->img2vec-pytorch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->img2vec-pytorch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->img2vec-pytorch) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->img2vec-pytorch) (3.0.2)\n",
            "Downloading img2vec_pytorch-1.0.1-py3-none-any.whl (6.9 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, img2vec-pytorch\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed img2vec-pytorch-1.0.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!pip install img2vec-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from img2vec_pytorch import Img2Vec\n",
        "from skimage.transform import resize\n",
        "from skimage.io import imread\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, classification_report, f1_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.svm import SVC\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import loguniform\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from PIL import Image\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from PIL import Image\n",
        "from sklearn.metrics import log_loss"
      ],
      "metadata": {
        "id": "ivZBSoabpNae"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img2vec = Img2Vec()\n",
        "input_dir = \"/content/drive/MyDrive/Python/garbage_classification\"\n",
        "# categories = ['cardboard', 'green-glass', 'metal', 'plastic']\n",
        "categories = ['cardboard', 'green-glass', 'metal']\n",
        "image_size = 224"
      ],
      "metadata": {
        "id": "f7Q-sAyngZtK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84789131-a141-4d07-8d83-099457769253"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 113MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data = {}\n",
        "labels = []\n",
        "features =[]\n",
        "\n",
        "for category_indx, category in enumerate(categories):\n",
        "    file_count = 0\n",
        "    for file in os.listdir(os.path.join(input_dir, category)):\n",
        "        # if file_count >= images_per_category:\n",
        "        #     break\n",
        "        img_path = os.path.join(input_dir, category, file)\n",
        "        img = imread(img_path)\n",
        "        img = resize(img, (image_size, image_size))\n",
        "        img = Image.fromarray((img * 255).astype(np.uint8))\n",
        "        img_features = img2vec.get_vec(img)\n",
        "        features.append(img_features)\n",
        "        labels.append(category_indx)\n",
        "        file_count += 1\n",
        "\n",
        "    # data[['input'][category_indx]] = features\n",
        "    # data[['output'][category_indx]] = features\n",
        "# data = np.asarray(data)\n",
        "features = np.asarray(features)\n",
        "labels = np.asarray(labels)"
      ],
      "metadata": {
        "id": "UmyK5mzYgjB1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total images loaded: {len(features)}\")\n",
        "for category_idx, category in enumerate(categories):\n",
        "    count = np.sum(labels == category_idx)\n",
        "    print(f\"{category}: {count} images\")\n",
        "print(f\"Feature vector length: {features.shape[1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTmyiZhcg-3I",
        "outputId": "0bcbbabb-fe43-495d-a7fd-fa01ab1bb554"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images loaded: 2289\n",
            "cardboard: 891 images\n",
            "green-glass: 629 images\n",
            "metal: 769 images\n",
            "Feature vector length: 512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_size=0.2\n",
        "val_size=0.2\n",
        "\n",
        "\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "    features,\n",
        "    labels,\n",
        "    test_size=test_size,\n",
        "    random_state=42,\n",
        "    stratify=labels\n",
        ")\n",
        "\n",
        "\n",
        "adjusted_val_size = val_size / (1 - test_size)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_temp,\n",
        "    y_temp,\n",
        "    test_size=adjusted_val_size,\n",
        "    random_state=42,\n",
        "    shuffle = True,\n",
        "    stratify=y_temp\n",
        ")\n",
        "\n",
        "\n",
        "print(f\"Total samples: {len(features)}\")\n",
        "print(f\"Training samples: {len(X_train)} ({len(X_train)/len(features):.1%})\")\n",
        "print(f\"Validation samples: {len(X_val)} ({len(X_val)/len(features):.1%})\")\n",
        "print(f\"Test samples: {len(X_test)} ({len(X_test)/len(features):.1%})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nikOtNV3g_xr",
        "outputId": "357eb4ec-b85c-4899-e16a-6c3af1a22eb0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total samples: 2289\n",
            "Training samples: 1373 (60.0%)\n",
            "Validation samples: 458 (20.0%)\n",
            "Test samples: 458 (20.0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  # K-Fold\n",
        "  n_splits = 5\n",
        "  random_state = 42\n",
        "  kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "\n",
        "  fold_scores = []\n",
        "  for fold, (train_idx, val_idx) in enumerate(kf.split(X_train), 1):\n",
        "      X_train_fold = X_train[train_idx]\n",
        "      y_train_fold = y_train[train_idx]\n",
        "      X_val_fold = X_train[val_idx]\n",
        "      y_val_fold = y_train[val_idx]\n",
        "\n",
        "      model = SVC()\n",
        "      parameters = [{'gamma':[0.01, 0.001, 0.0001], 'C': [1, 10, 100, 1000]}]\n",
        "\n",
        "      gread_search = GridSearchCV(model, parameters)\n",
        "      gread_search.fit(X_train_fold, y_train_fold)\n",
        "      y_pred = gread_search.best_estimator_.predict(X_val_fold)\n",
        "\n",
        "      fold_accuracy = accuracy_score(y_val_fold, y_pred)\n",
        "      fold_scores.append(fold_accuracy)\n",
        "\n",
        "      # print(f\"Fold {fold} Accuracy: {fold_accuracy:.4f}\")\n",
        "\n",
        "\n",
        "      fold_f1 = f1_score(y_val_fold, y_pred, average='weighted')\n",
        "      fold_precision = precision_score(y_val_fold, y_pred, average='weighted')\n",
        "      fold_recall = recall_score(y_val_fold, y_pred, average='weighted')\n",
        "\n",
        "      fold_scores.append(fold_accuracy)\n",
        "\n",
        "      print(f\"Fold {fold} - Accuracy: {fold_accuracy:.4f}, F1-Score: {fold_f1:.4f}, Precision: {fold_precision:.4f}, Recall: {fold_recall:.4f}\")\n",
        "\n",
        "\n",
        "  # model = SVC()\n",
        "  # model.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGza3tS7hJuf",
        "outputId": "35027282-40f8-4250-bd33-8c825cc39fed"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 - Accuracy: 0.9891, F1-Score: 0.9891, Precision: 0.9892, Recall: 0.9891\n",
            "Fold 2 - Accuracy: 0.9818, F1-Score: 0.9818, Precision: 0.9821, Recall: 0.9818\n",
            "Fold 3 - Accuracy: 0.9745, F1-Score: 0.9747, Precision: 0.9762, Recall: 0.9745\n",
            "Fold 4 - Accuracy: 0.9781, F1-Score: 0.9781, Precision: 0.9782, Recall: 0.9781\n",
            "Fold 5 - Accuracy: 0.9854, F1-Score: 0.9854, Precision: 0.9856, Recall: 0.9854\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cv_mean = np.mean(fold_scores)\n",
        "cv_std = np.std(fold_scores)\n",
        "print(f\"\\nCross-validation Mean Accuracy: {cv_mean:.4f} (±{cv_std:.4f})\")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "val_score = accuracy_score(y_val, model.predict(X_val))\n",
        "test_score = accuracy_score(y_test, model.predict(X_test))\n",
        "\n",
        "print(f\"Validation Set Accuracy: {val_score:.4f}\")\n",
        "print(f\"Test Set Accuracy: {test_score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BxfcD_Cekra",
        "outputId": "81803ab5-1b61-4ab4-b5cf-522aaab6f69b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cross-validation Mean Accuracy: 0.9818 (±0.0051)\n",
            "Validation Set Accuracy: 0.9782\n",
            "Test Set Accuracy: 0.9803\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fold_losses = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train), 1):\n",
        "    X_train_fold = X_train[train_idx]\n",
        "    y_train_fold = y_train[train_idx]\n",
        "    X_val_fold = X_train[val_idx]\n",
        "    y_val_fold = y_train[val_idx]\n",
        "    model = SVC(probability=True)\n",
        "    parameters = [{'gamma':[0.01, 0.001, 0.0001], 'C': [1, 10, 100, 1000]}]\n",
        "    gread_search = GridSearchCV(model, parameters)\n",
        "    gread_search.fit(X_train_fold, y_train_fold)\n",
        "    # model = RandomForestClassifier()\n",
        "    # model.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    y_val_proba = gread_search.best_estimator_.predict_proba(X_val_fold)\n",
        "    fold_loss = log_loss(y_val_fold, y_val_proba)\n",
        "\n",
        "    fold_losses.append(fold_loss)\n",
        "    print(f\"Fold {fold} Log Loss: {fold_loss:.4f}\")\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(range(1, len(fold_losses) + 1), fold_losses, marker='o', linestyle='-', color='r', label='Validation Log Loss')\n",
        "plt.xlabel('Fold')\n",
        "plt.ylabel('Log Loss')\n",
        "plt.title(f'{n_splits}-Fold Cross-Validation Log Loss')\n",
        "plt.ylim(0, max(fold_losses) + 0.1)\n",
        "plt.xticks(range(1, len(fold_losses) + 1))\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5l8gdWYkhRAn",
        "outputId": "80596b41-54d7-4e88-97bf-1c8fce5776fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Log Loss: 0.0354\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(range(1, n_splits + 1), fold_scores, marker='o', linestyle='-', color='b', label='Validation Accuracy')\n",
        "plt.xlabel('Fold')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title(f'{n_splits}-Fold Cross-Validation Accuracy')\n",
        "plt.ylim(0, 1)\n",
        "plt.xticks(range(1, n_splits + 1))\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "beeFlbcMfQEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lpPOKtcAg8lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fold_losses = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train), 1):\n",
        "    X_train_fold = X_train[train_idx]\n",
        "    y_train_fold = y_train[train_idx]\n",
        "    X_val_fold = X_train[val_idx]\n",
        "    y_val_fold = y_train[val_idx]\n",
        "\n",
        "    model = RandomForestClassifier()\n",
        "    model.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    y_val_proba = model.predict_proba(X_val_fold)\n",
        "    fold_loss = log_loss(y_val_fold, y_val_proba)\n",
        "\n",
        "    fold_losses.append(fold_loss)\n",
        "    print(f\"Fold {fold} Log Loss: {fold_loss:.4f}\")\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(range(1, len(fold_losses) + 1), fold_losses, marker='o', linestyle='-', color='r', label='Validation Log Loss')\n",
        "plt.xlabel('Fold')\n",
        "plt.ylabel('Log Loss')\n",
        "plt.title(f'{n_splits}-Fold Cross-Validation Log Loss')\n",
        "plt.ylim(0, max(fold_losses) + 0.1)\n",
        "plt.xticks(range(1, len(fold_losses) + 1))\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "Eo3oo_Ntezje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Perform K-Fold Cross-Validation\n",
        "# n_splits = 5\n",
        "# random_state = 42\n",
        "# kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "\n",
        "# fold_scores = []\n",
        "# for fold, (train_idx, val_idx) in enumerate(kf.split(X_train), 1):\n",
        "#     print(f\"Training on Fold {fold}...\")\n",
        "\n",
        "#     # Split training data for this fold\n",
        "#     X_train_fold, y_train_fold = X_train[train_idx], y_train[train_idx]\n",
        "#     X_val_fold, y_val_fold = X_train[val_idx], y_train[val_idx]\n",
        "\n",
        "#     # Train model using RandomizedSearchCV\n",
        "#     random_search.fit(X_train_fold, y_train_fold)\n",
        "#     best_random_model = random_search.best_estimator_\n",
        "\n",
        "#     # Train model using GridSearchCV\n",
        "#     grid_search.fit(X_train_fold, y_train_fold)\n",
        "#     best_grid_model = grid_search.best_estimator_\n",
        "\n",
        "#     # Store best model performance for this fold\n",
        "#     fold_scores.append({\n",
        "#         \"fold\": fold,\n",
        "#         \"best_random_params\": random_search.best_params_,\n",
        "#         \"best_grid_params\": grid_search.best_params_,\n",
        "#         \"random_score\": best_random_model.score(X_val_fold, y_val_fold),\n",
        "#         \"grid_score\": best_grid_model.score(X_val_fold, y_val_fold)\n",
        "#     })\n",
        "\n",
        "# # Print results\n",
        "# for result in fold_scores:\n",
        "#     print(f\"Fold {result['fold']}:\")\n",
        "#     print(f\"  Best RandomizedSearch Params: {result['best_random_params']}\")\n",
        "#     print(f\"  Best GridSearch Params: {result['best_grid_params']}\")\n",
        "#     print(f\"  RandomizedSearch Score: {result['random_score']:.4f}\")\n",
        "#     print(f\"  GridSearch Score: {result['grid_score']:.4f}\")\n",
        "\n",
        "# # Select the best overall model\n",
        "# best_model = max(fold_scores, key=lambda x: x[\"grid_score\"])[\"best_grid_params\"]\n",
        "# print(f\"\\nBest overall model parameters: {best_model}\")"
      ],
      "metadata": {
        "id": "B5fHsf4hY60C",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_pred = random_search.predict(X_val_fold)\n",
        "y_pred = gread_search.predict(X_val_fold)\n",
        "fold_accuracy = accuracy_score(y_val_fold, y_pred)\n",
        "fold_scores.append(fold_accuracy)\n",
        "print(f\"Fold {fold} Accuracy: {fold_accuracy:.4f}\")\n",
        "# print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "print(\"\\nDetailed classification report:\")\n",
        "print(classification_report(y_val_fold, y_pred, target_names=categories))"
      ],
      "metadata": {
        "id": "Uq3GwXoYvs8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(range(1, n_splits + 1), fold_scores, marker='o', linestyle='-', color='b', label='Validation Accuracy')\n",
        "plt.xlabel('Fold')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title(f'{n_splits}-Fold Cross-Validation Accuracy')\n",
        "plt.ylim(0, 1)\n",
        "plt.xticks(range(1, n_splits + 1))\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mWZACfWWYKsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "cm = confusion_matrix(y_val_fold, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens',\n",
        "            xticklabels=categories,\n",
        "            yticklabels=categories)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_bNMTBRuwNz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_mean = np.mean(fold_scores)\n",
        "cv_std = np.std(fold_scores)\n",
        "print(f\"\\nCross-validation Mean Accuracy: {cv_mean:.4f} (±{cv_std:.4f})\")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "val_score = accuracy_score(y_val, model.predict(X_val))\n",
        "test_score = accuracy_score(y_test, model.predict(X_test))\n",
        "\n",
        "print(f\"Validation Set Accuracy: {val_score:.4f}\")\n",
        "print(f\"Test Set Accuracy: {test_score:.4f}\")\n"
      ],
      "metadata": {
        "id": "hQXhzulRwfac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv=5\n",
        "n_points=10\n",
        "train_sizes = np.linspace(0.1, 1.0, n_points)\n",
        "train_scores = []\n",
        "val_scores = []\n",
        "\n",
        "for size in train_sizes:\n",
        "    n_samples = int(len(X_train) * size)\n",
        "\n",
        "\n",
        "    cv_scores = cross_val_score(\n",
        "        model, X_train[:n_samples], y_train[:n_samples],\n",
        "        cv=cv, n_jobs=-1\n",
        "    )\n",
        "\n",
        "\n",
        "    model.fit(X_train[:n_samples], y_train[:n_samples])\n",
        "    val_score = model.score(X_val, y_val)\n",
        "\n",
        "    train_scores.append(cv_scores)\n",
        "    val_scores.append(val_score)\n",
        "\n",
        "train_scores = np.array(train_scores)\n",
        "val_scores = np.array(val_scores)\n",
        "\n",
        "\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "val_mean = val_scores\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plt.plot(train_sizes * len(X_train), train_mean,\n",
        "         label='Training Score', color='blue', marker='o')\n",
        "plt.fill_between(train_sizes * len(X_train),\n",
        "                 train_mean - train_std, train_mean + train_std,\n",
        "                 alpha=0.15, color='blue')\n",
        "\n",
        "plt.plot(train_sizes * len(X_train), val_mean,\n",
        "         label='Validation Score', color='green', marker='o')\n",
        "\n",
        "plt.xlabel('Training Examples')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Learning Curves')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True)\n",
        "\n",
        "\n",
        "plt.text(0.02, 0.02,\n",
        "         f'Final Training Score: {train_mean[-1]:.4f}\\n'\n",
        "         f'Final Validation Score: {val_mean[-1]:.4f}',\n",
        "         transform=plt.gca().transAxes,\n",
        "         bbox=dict(facecolor='white', alpha=0.8))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "YrCg9kWcwhzu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}